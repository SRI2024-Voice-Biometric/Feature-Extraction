{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport librosa\nimport librosa.display\nfrom scipy.signal import lfilter,correlate\nimport tensorflow.keras.layers as tfl\nimport tensorflow as tf\nfrom keras.callbacks import ReduceLROnPlateau\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2024-06-21T20:03:09.855909Z","iopub.execute_input":"2024-06-21T20:03:09.856271Z","iopub.status.idle":"2024-06-21T20:03:19.777827Z","shell.execute_reply.started":"2024-06-21T20:03:09.856240Z","shell.execute_reply":"2024-06-21T20:03:19.776785Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-06-21 20:03:13.429461: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-21 20:03:13.429584: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-21 20:03:13.562659: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"def pre_emphasis(signal,factor=0.97):\n    return np.append(signal[0], signal[1:] - factor * signal[:-1])","metadata":{"execution":{"iopub.status.busy":"2024-06-21T18:39:58.981161Z","iopub.execute_input":"2024-06-21T18:39:58.981832Z","iopub.status.idle":"2024-06-21T18:39:58.986870Z","shell.execute_reply.started":"2024-06-21T18:39:58.981798Z","shell.execute_reply":"2024-06-21T18:39:58.985943Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def inverse_filtering(signal, lpc_coeffs):\n    return lfilter(np.concatenate(([1], -lpc_coeffs[1:])), [1], signal)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T18:39:59.684235Z","iopub.execute_input":"2024-06-21T18:39:59.684658Z","iopub.status.idle":"2024-06-21T18:39:59.689362Z","shell.execute_reply.started":"2024-06-21T18:39:59.684624Z","shell.execute_reply":"2024-06-21T18:39:59.688450Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def compute_lpc(signal, order):\n    autocorr = correlate(signal, signal, mode='full')\n    autocorr = autocorr[len(signal)-1:len(signal)+order]\n    \n    a = np.concatenate(([1], -autocorr[1:order+1]))\n    b = [1]\n    \n    lpc_coeffs = lfilter(b, a, signal)\n    \n    lpc_coeffs = np.concatenate(([1], -lpc_coeffs[1:order+1]))\n    \n    del autocorr,a,b\n    \n    return lpc_coeffs","metadata":{"execution":{"iopub.status.busy":"2024-06-21T18:40:00.200025Z","iopub.execute_input":"2024-06-21T18:40:00.201243Z","iopub.status.idle":"2024-06-21T18:40:00.207244Z","shell.execute_reply.started":"2024-06-21T18:40:00.201206Z","shell.execute_reply":"2024-06-21T18:40:00.206345Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def lpc_to_cepstrum(lpc_coeffs):\n    return np.fft.ifft(np.log(np.abs(np.fft.fft(lpc_coeffs))))","metadata":{"execution":{"iopub.status.busy":"2024-06-21T18:40:00.642947Z","iopub.execute_input":"2024-06-21T18:40:00.643322Z","iopub.status.idle":"2024-06-21T18:40:00.648068Z","shell.execute_reply.started":"2024-06-21T18:40:00.643282Z","shell.execute_reply":"2024-06-21T18:40:00.647135Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import gc\nfrom IPython.display import clear_output\n\ndef create_spectrograms(train_folder, create_folder, verbose=False, speakers=50, utterances=10, sr=7000, frame_length=2048, hop_length=512, lpc_order=16):\n    spc_folder = os.path.join(create_folder, \"spectrogram\")\n    vt_folder = os.path.join(create_folder, \"vocal_tract\")\n    glot_folder = os.path.join(create_folder, \"glottal\")\n    \n    total_speaker = 0\n    for speaker in os.listdir(train_folder):\n        total_utterances = 0\n        speaker_folder_spc = os.path.join(spc_folder, speaker)\n        speaker_folder_vt = os.path.join(vt_folder, speaker)\n        speaker_folder_glot = os.path.join(glot_folder, speaker)\n        os.makedirs(speaker_folder_spc, exist_ok=True)\n        os.makedirs(speaker_folder_vt, exist_ok=True)\n        os.makedirs(speaker_folder_glot, exist_ok=True)\n        \n        for vidID in os.listdir(os.path.join(train_folder, speaker)):\n            for file in os.listdir(os.path.join(train_folder, speaker, vidID)):\n                if file.endswith(\".wav\"):\n                    wav_file_path = os.path.join(train_folder, speaker, vidID, file)\n                    \n                    y, sr = librosa.load(wav_file_path, sr=sr)\n                    \n#                     y_preemphasized=pre_emphasis(y)\n                    y_preemphasized=y\n                    \n                    frames = librosa.util.frame(y_preemphasized, frame_length=frame_length, hop_length=hop_length).T\n                    del y_preemphasized\n                    \n                    window = np.hamming(frame_length)\n                    frames_windowed = frames * window  \n                    del frames\n                    \n                    lpc_coeffs = []\n                    for frame in frames_windowed:\n                        frame=np.array(frame)\n                        coeff = compute_lpc(frame, lpc_order)\n                        lpc_coeffs.append(coeff)\n                        \n                    glottal_waveforms = [inverse_filtering(frame, coeff) for frame, coeff in zip(frames_windowed, lpc_coeffs)]\n                    glottal_waveforms_avg = np.mean(np.abs(np.array(glottal_waveforms)), axis=0)\n                    del glottal_waveforms\n                    \n                    residuals = []\n                    for i, coeff in enumerate(lpc_coeffs):\n                        frame = frames_windowed[i]\n                        residual = lfilter(coeff, [1.0], frame)\n                        residuals.append(residual)\n                        \n                    residual_avg = np.mean(np.abs(np.array(residuals)), axis=0)\n                    \n                    del frames_windowed, lpc_coeffs, residuals\n                    gc.collect()\n\n                    try:\n                        plt.figure(figsize=(5, 5))\n                        ax = plt.axes()\n                        ax.set_axis_off()\n                        plt.set_cmap('hot')\n                        amp=np.abs(librosa.stft(y))\n                        D = librosa.amplitude_to_db(amp, ref=np.max)\n                        del y,amp\n                        librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log')\n                        output_path = os.path.join(speaker_folder_spc, \"spc\"+str(total_utterances+1) + \".png\")\n                        plt.savefig(output_path, bbox_inches='tight', transparent=True, pad_inches=0.0)\n                        plt.close('all')\n                        del D,ax,output_path\n                        gc.collect()\n\n                        plt.figure(figsize=(5, 5))\n                        ax = plt.axes()\n                        ax.set_axis_off()\n                        plt.set_cmap('hot')\n                        amp=np.abs(librosa.stft(residual_avg))\n                        D_residual = librosa.amplitude_to_db(amp, ref=np.max)\n                        del amp\n                        librosa.display.specshow(D_residual, sr=sr, x_axis='time', y_axis='log')\n                        output_path = os.path.join(speaker_folder_vt, \"vt\"+str(total_utterances+1) + \".png\")\n                        plt.savefig(output_path, bbox_inches='tight', transparent=True, pad_inches=0.0)\n                        plt.close('all')\n                        del D_residual,ax,output_path\n                        gc.collect()\n\n                        plt.figure(figsize=(5, 5))\n                        ax = plt.axes()\n                        ax.set_axis_off()\n                        plt.set_cmap('hot')\n                        amp=np.abs(librosa.stft(glottal_waveforms_avg))\n                        D_glot = librosa.amplitude_to_db(amp, ref=np.max)\n                        del amp\n                        librosa.display.specshow(D_glot, sr=sr, x_axis='time', y_axis='log')\n                        output_path = os.path.join(speaker_folder_glot, \"glot\"+str(total_utterances+1) + \".png\")\n                        plt.savefig(output_path, bbox_inches='tight', transparent=True, pad_inches=0.0)\n                        plt.close('all')\n                        del D_glot,ax,output_path\n                        gc.collect()\n                        \n#                         clear_output()\n                    \n                    except OSError as e:\n                        print(f\"Error saving spectrogram for {wav_file_path}: {e}\")\n                    \n                    del residual_avg, glottal_waveforms_avg\n                    gc.collect()\n    \n                    total_utterances += 1\n                    if total_utterances == utterances:\n                        break\n            \n            if total_utterances == utterances:\n                break\n        \n        total_speaker += 1\n        if total_speaker != 0 and total_speaker % 1 == 0 and verbose:\n            print(f\"{total_speaker} speakers completed.\\n\")\n        \n        if total_speaker == speakers:\n            break","metadata":{"execution":{"iopub.status.busy":"2024-06-21T18:40:01.067826Z","iopub.execute_input":"2024-06-21T18:40:01.068185Z","iopub.status.idle":"2024-06-21T18:40:01.094537Z","shell.execute_reply.started":"2024-06-21T18:40:01.068156Z","shell.execute_reply":"2024-06-21T18:40:01.093643Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"raw_dataset_loc=\"/kaggle/input/voxceleb1train/wav\"\nsave_loc=\"/kaggle/working/\"\nnum_speakers=10\nnum_utterances=100","metadata":{"execution":{"iopub.status.busy":"2024-06-21T20:03:31.293362Z","iopub.execute_input":"2024-06-21T20:03:31.294911Z","iopub.status.idle":"2024-06-21T20:03:31.299659Z","shell.execute_reply.started":"2024-06-21T20:03:31.294860Z","shell.execute_reply":"2024-06-21T20:03:31.298737Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"create_spectrograms(raw_dataset_loc,save_loc,True,num_speakers,num_utterances)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T18:40:03.113916Z","iopub.execute_input":"2024-06-21T18:40:03.114274Z","iopub.status.idle":"2024-06-21T19:59:20.647139Z","shell.execute_reply.started":"2024-06-21T18:40:03.114248Z","shell.execute_reply":"2024-06-21T19:59:20.646160Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"1 speakers completed.\n\n2 speakers completed.\n\n3 speakers completed.\n\n4 speakers completed.\n\n5 speakers completed.\n\n6 speakers completed.\n\n7 speakers completed.\n\n8 speakers completed.\n\n9 speakers completed.\n\n10 speakers completed.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset_path_spc=\"/kaggle/working/spectrogram\"\ndataset_path_vt=\"/kaggle/working/vocal_tract\"\ndataset_path_glot=\"/kaggle/working/glottal\"\nfolders=os.listdir(dataset_path_spc)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T20:03:36.718475Z","iopub.execute_input":"2024-06-21T20:03:36.719340Z","iopub.status.idle":"2024-06-21T20:03:36.724400Z","shell.execute_reply.started":"2024-06-21T20:03:36.719309Z","shell.execute_reply":"2024-06-21T20:03:36.723366Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"dict={}\ni=0\nfor val in folders:\n    dict[val]=i\n    i=i+1\n\ndict","metadata":{"execution":{"iopub.status.busy":"2024-06-21T20:03:37.654207Z","iopub.execute_input":"2024-06-21T20:03:37.655050Z","iopub.status.idle":"2024-06-21T20:03:37.662854Z","shell.execute_reply.started":"2024-06-21T20:03:37.655018Z","shell.execute_reply":"2024-06-21T20:03:37.661956Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"{'id11079': 0,\n 'id10719': 1,\n 'id10036': 2,\n 'id10480': 3,\n 'id10484': 4,\n 'id10459': 5,\n 'id10116': 6,\n 'id10061': 7,\n 'id11123': 8,\n 'id11250': 9}"},"metadata":{}}]},{"cell_type":"code","source":"dataset_path_spc=\"/kaggle/working/spectrogram\"\ndataset_path_vt=\"/kaggle/working/vocal_tract\"\ndataset_path_glot=\"/kaggle/working/glottal\"\nfolders=os.listdir(dataset_path_spc)\n\n# Initializing training and test dataset\nX_train=[[],[],[]]\ny_train=[[],[],[]]\nX_test=[[],[],[]]\ny_test=[[],[],[]]\n\n# Split the dataset into training and test set.\nnum=np.random.rand(num_utterances*num_speakers)\nmask=num<0.2\nsplit=mask.astype(int)\n\nfor dirs in folders:\n    i=0\n    for img in os.listdir(os.path.join(dataset_path_spc,dirs)):\n        image=Image.open(os.path.join(dataset_path_spc,dirs,img))\n        new_img=image.resize((200,200))\n        tmp_array=np.array(new_img)/255.\n        if split[i]==0:\n            X_train[0].append(tmp_array)\n            y_train[0].append(dict[str(dirs)])\n        else:\n            X_test[0].append(tmp_array)\n            y_test[0].append(dict[str(dirs)])\n            \n        i+=1\n        \n    i=0    \n    for img in os.listdir(os.path.join(dataset_path_vt,dirs)):\n        image=Image.open(os.path.join(dataset_path_vt,dirs,img))\n        new_img=image.resize((200,200))\n        tmp_array=np.array(new_img)/255.\n        if split[i]==0:\n            X_train[1].append(tmp_array)\n            y_train[1].append(dict[str(dirs)])\n        else:\n            X_test[1].append(tmp_array)\n            y_test[1].append(dict[str(dirs)])\n            \n        i+=1\n            \n    i=0\n    for img in os.listdir(os.path.join(dataset_path_glot,dirs)):\n        image=Image.open(os.path.join(dataset_path_glot,dirs,img))\n        new_img=image.resize((200,200))\n        tmp_array=np.array(new_img)/255.\n        if split[i]==0:\n            X_train[2].append(tmp_array)\n            y_train[2].append(dict[str(dirs)])\n        else:\n            X_test[2].append(tmp_array)\n            y_test[2].append(dict[str(dirs)])\n        \n        i+=1","metadata":{"execution":{"iopub.status.busy":"2024-06-21T20:03:48.407419Z","iopub.execute_input":"2024-06-21T20:03:48.407816Z","iopub.status.idle":"2024-06-21T20:04:08.254806Z","shell.execute_reply.started":"2024-06-21T20:03:48.407784Z","shell.execute_reply":"2024-06-21T20:04:08.253906Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def create_train_triplets(X_train, y_train, num_triplets):\n    triplets = []\n    labels = np.unique(y_train)\n    \n    for _ in range(num_triplets):\n        anchor_label = np.random.choice(labels)\n        negative_label = np.random.choice(labels[labels != anchor_label])\n        \n        anchor_indices = np.where(y_train == anchor_label)[0]\n        positive_indices = np.where(y_train == anchor_label)[0]\n        negative_indices = np.where(y_train == negative_label)[0]\n        \n        anchor = X_train[np.random.choice(anchor_indices)]\n        positive = X_train[np.random.choice(positive_indices)]\n        negative = X_train[np.random.choice(negative_indices)]\n        \n        triplets.append((anchor, positive, negative))\n    \n    return np.array(triplets)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T20:04:08.256690Z","iopub.execute_input":"2024-06-21T20:04:08.257146Z","iopub.status.idle":"2024-06-21T20:04:08.264424Z","shell.execute_reply.started":"2024-06-21T20:04:08.257109Z","shell.execute_reply":"2024-06-21T20:04:08.263493Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def create_test_triplets(X_test, y_test, num_triplets):\n    triplets = []\n    range_test = len(y_test)\n    idx = np.arange(range_test)\n    \n    for _ in range(num_triplets):\n        label_1 = np.random.choice(idx)\n        label_2 = np.random.choice(idx)\n        \n        anchor = X_test[label_1]\n        inp = X_test[label_2]\n        out = 1 if y_test[label_1] == y_test[label_2] else 0\n        \n        triplets.append((anchor, inp, out))\n        \n    return np.array(triplets, dtype=object)  ","metadata":{"execution":{"iopub.status.busy":"2024-06-21T20:15:23.452660Z","iopub.execute_input":"2024-06-21T20:15:23.453088Z","iopub.status.idle":"2024-06-21T20:15:23.460037Z","shell.execute_reply.started":"2024-06-21T20:15:23.453049Z","shell.execute_reply":"2024-06-21T20:15:23.459006Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def convolutional_model(input_shape):\n    input_img = tf.keras.Input(shape=input_shape)\n    Z1=tfl.Conv2D(filters=32,kernel_size=(3,3),strides=(1,1),padding='same')(input_img)\n    A1=tfl.ReLU()(Z1)\n    P1=tfl.MaxPool2D(pool_size=(4,4),padding='same')(A1)\n    Z2=tfl.Conv2D(filters=64,kernel_size=(2,2),strides=(1,1),padding='same')(P1)\n    A2=tfl.ReLU()(Z2)\n    P2=tfl.MaxPool2D(pool_size=(4,4),padding='same')(A2)\n    Z3=tfl.Conv2D(filters=128,kernel_size=(2,2),strides=(1,1),padding='same')(P2)\n    A3=tfl.ReLU()(Z3)\n    P3=tfl.MaxPool2D(pool_size=(4,4),padding='same')(A3)\n    F=tfl.Flatten()(P3)\n    D1=tfl.Dense(128)(F)\n        \n    model = tf.keras.Model(inputs=input_img, outputs=D1)\n    return model\n\ninput_shape = (200, 200, 4)\nbase_model = convolutional_model(input_shape)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T20:04:13.638951Z","iopub.execute_input":"2024-06-21T20:04:13.640015Z","iopub.status.idle":"2024-06-21T20:04:14.459716Z","shell.execute_reply.started":"2024-06-21T20:04:13.639977Z","shell.execute_reply":"2024-06-21T20:04:14.458728Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def triplet_loss(y_true, y_pred, margin=1.0):\n    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n    pos_dist = tf.reduce_sum(tf.square(anchor - positive), axis=-1)\n    neg_dist = tf.reduce_sum(tf.square(anchor - negative), axis=-1)\n    loss = tf.maximum(pos_dist - neg_dist + margin, 0.0)\n    return tf.reduce_mean(loss)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-21T20:04:16.111893Z","iopub.execute_input":"2024-06-21T20:04:16.112581Z","iopub.status.idle":"2024-06-21T20:04:16.118534Z","shell.execute_reply.started":"2024-06-21T20:04:16.112542Z","shell.execute_reply":"2024-06-21T20:04:16.117469Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"anchor_input = tfl.Input(shape=input_shape, name='anchor_input')\npositive_input = tfl.Input(shape=input_shape, name='positive_input')\nnegative_input = tfl.Input(shape=input_shape, name='negative_input')\n\nencoded_anchor = base_model(anchor_input)\nencoded_positive = base_model(positive_input)\nencoded_negative = base_model(negative_input)\n\ntriplet_model_spc = tf.keras.Model(inputs=[anchor_input, positive_input, negative_input],\n                      outputs=[encoded_anchor, encoded_positive, encoded_negative])\n\ntriplet_model_spc.compile(optimizer='adam', loss=triplet_loss)\n\ntriplet_model_vt = tf.keras.Model(inputs=[anchor_input, positive_input, negative_input],\n                      outputs=[encoded_anchor, encoded_positive, encoded_negative])\n\ntriplet_model_vt.compile(optimizer='adam', loss=triplet_loss)\n\ntriplet_model_glot = tf.keras.Model(inputs=[anchor_input, positive_input, negative_input],\n                      outputs=[encoded_anchor, encoded_positive, encoded_negative])\n\ntriplet_model_glot.compile(optimizer='adam', loss=triplet_loss)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T20:04:19.720719Z","iopub.execute_input":"2024-06-21T20:04:19.721086Z","iopub.status.idle":"2024-06-21T20:04:19.759802Z","shell.execute_reply.started":"2024-06-21T20:04:19.721056Z","shell.execute_reply":"2024-06-21T20:04:19.759062Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"triplets_spc=create_train_triplets(X_train[0],y_train[0],500)\n\nanchor_images = triplets_spc[:, 0]\npositive_images = triplets_spc[:, 1]\nnegative_images = triplets_spc[:, 2]\n\ntriplet_model_spc.fit([anchor_images, positive_images, negative_images], \n                  np.zeros((500, )),\n                  batch_size=32, \n                  epochs=100)","metadata":{"execution":{"iopub.status.busy":"2024-06-21T20:05:03.510120Z","iopub.execute_input":"2024-06-21T20:05:03.520501Z","iopub.status.idle":"2024-06-21T20:05:55.009528Z","shell.execute_reply.started":"2024-06-21T20:05:03.520464Z","shell.execute_reply":"2024-06-21T20:05:55.008642Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Epoch 1/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 1.0041\nEpoch 2/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 1.0015\nEpoch 3/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.0001\nEpoch 4/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.9865\nEpoch 5/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.9802\nEpoch 6/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.9270\nEpoch 7/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.0954\nEpoch 8/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.0078\nEpoch 9/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.0127\nEpoch 10/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.0250\nEpoch 11/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.0150\nEpoch 12/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.0096\nEpoch 13/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.9547\nEpoch 14/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.1574\nEpoch 15/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.0436\nEpoch 16/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.9698\nEpoch 17/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.8592\nEpoch 18/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.1289\nEpoch 19/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.0147\nEpoch 20/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.0011\nEpoch 21/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.9921\nEpoch 22/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.0088\nEpoch 23/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.0036\nEpoch 24/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.0173\nEpoch 25/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.9911\nEpoch 26/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.9965\nEpoch 27/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.9761\nEpoch 28/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.2731\nEpoch 29/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.9648\nEpoch 30/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.9613\nEpoch 31/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.0294\nEpoch 32/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.0203\nEpoch 33/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.0109\nEpoch 34/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.0186\nEpoch 35/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.0288\nEpoch 36/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.0243\nEpoch 37/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.0039\nEpoch 38/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.0000\nEpoch 39/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.9839\nEpoch 40/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.9941\nEpoch 41/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.9996\nEpoch 42/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 1.0213\nEpoch 43/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.0023\nEpoch 44/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.0317\nEpoch 45/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.9983\nEpoch 46/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.9945\nEpoch 47/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.0183\nEpoch 48/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.9987\nEpoch 49/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.9981\nEpoch 50/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.0061\nEpoch 51/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.9865\nEpoch 52/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.9753\nEpoch 53/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.9535\nEpoch 54/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.2297\nEpoch 55/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.9782\nEpoch 56/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 1.0016\nEpoch 57/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.0008\nEpoch 58/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.9949\nEpoch 59/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.0194\nEpoch 60/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.0030\nEpoch 61/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.0035\nEpoch 62/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.9978\nEpoch 63/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.9953\nEpoch 64/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 1.0039\nEpoch 65/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.0024\nEpoch 66/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.0010\nEpoch 67/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.0075\nEpoch 68/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.9986\nEpoch 69/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.0000\nEpoch 70/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.0045\nEpoch 71/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.0041\nEpoch 72/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.9988\nEpoch 73/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.0026\nEpoch 74/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.0018\nEpoch 75/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.0012\nEpoch 76/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.9999\nEpoch 77/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.0009\nEpoch 78/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.9979\nEpoch 79/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.0023\nEpoch 80/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.0022\nEpoch 81/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.9946\nEpoch 82/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.0008\nEpoch 83/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.9993\nEpoch 84/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.0024\nEpoch 85/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.9929\nEpoch 86/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.9980\nEpoch 87/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.9941\nEpoch 88/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.9961\nEpoch 89/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.0043\nEpoch 90/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.9973\nEpoch 91/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.9987\nEpoch 92/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.0004\nEpoch 93/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.9958\nEpoch 94/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.9999\nEpoch 95/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.0021\nEpoch 96/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.0026\nEpoch 97/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.0018\nEpoch 98/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.9983\nEpoch 99/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.0034\nEpoch 100/100\n\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.9966\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7b0d641fce50>"},"metadata":{}}]},{"cell_type":"code","source":"triplets_spc_test=create_test_triplets(X_test[0],y_test[0],100)\n\nanchor_images = triplets_spc_test[:, 0]\ninput_images = triplets_spc_test[:, 1]\nlabel_test_spc = triplets_spc_test[:, 2]","metadata":{"execution":{"iopub.status.busy":"2024-06-21T20:15:28.434393Z","iopub.execute_input":"2024-06-21T20:15:28.435082Z","iopub.status.idle":"2024-06-21T20:15:28.445770Z","shell.execute_reply.started":"2024-06-21T20:15:28.435047Z","shell.execute_reply":"2024-06-21T20:15:28.444671Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"true_pos = 0\nnum_triplets = 100  \n\ntriplets_test = create_test_triplets(X_test[0], y_test[0], num_triplets)\n\nanchor_input_test = np.stack(triplets_test[:, 0])\npositive_input_test = np.stack(triplets_test[:, 1])\nlabels_test = triplets_test[:, 2]\n\nencoded_anchor = base_model.predict(anchor_input_test)\nencoded_positive = base_model.predict(positive_input_test)\n\ndistances = np.linalg.norm(encoded_anchor - encoded_positive, axis=1)\n\nthreshold = 1.7\n\nfor i in range(num_triplets):\n    if distances[i] > threshold and labels_test[i] == 1:\n        true_pos += 1\n    if distances[i] <= threshold and labels_test[i] == 0:\n        true_pos += 1\n\naccuracy = true_pos / num_triplets\nprint(\"Accuracy: {:.2f}\".format(accuracy))\n","metadata":{"execution":{"iopub.status.busy":"2024-06-21T20:25:07.408272Z","iopub.execute_input":"2024-06-21T20:25:07.409266Z","iopub.status.idle":"2024-06-21T20:25:09.241046Z","shell.execute_reply.started":"2024-06-21T20:25:07.409222Z","shell.execute_reply":"2024-06-21T20:25:09.240096Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 273ms/step\n\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \nAccuracy: 0.90\n","output_type":"stream"}]},{"cell_type":"code","source":"import zipfile\n\n# Define the paths\nsource_path = '/kaggle/working'  # Source directory in Kaggle\nzip_filename = 'saved_data.zip'  # Name for the zip file\n\n# Create a zip archive\nwith zipfile.ZipFile(zip_filename, 'w') as zipf:\n    # Add all files in source_path to the zip\n    for root, _, files in os.walk(source_path):\n        for file in files:\n            zipf.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), source_path))\n","metadata":{"execution":{"iopub.status.busy":"2024-06-21T20:27:21.583006Z","iopub.execute_input":"2024-06-21T20:27:21.583458Z","iopub.status.idle":"2024-06-21T20:27:22.145000Z","shell.execute_reply.started":"2024-06-21T20:27:21.583426Z","shell.execute_reply":"2024-06-21T20:27:22.143983Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}